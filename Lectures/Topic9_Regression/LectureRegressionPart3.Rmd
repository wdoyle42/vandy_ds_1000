---
title: "Regression: Feature Selection"
author: "Will Doyle"
---

## Introduction

In this last lecture we'll introduce a couple of new concepts: cross validation and feature selection.


```{r}
library(tidyverse)
library(tidymodels)
library(knitr)
library(plotly)
library(modelr)
```

## The Data

We're going to work with a subset of the data that only includes a few variables, which are selected below. 

```{r}
mv<-readRDS("mv.Rds")%>%
  filter(!is.na(budget))%>%
  mutate(log_gross=log(gross))%>%
  mutate(year=as_factor(year))%>%
  select(title,
    log_gross,
         budget,
         rating,
         genre,
         runtime,
         year)%>%
  drop_na()
```

As usual, we'll split the data 75/25. 

```{r}
split_data<-initial_split(mv)

mv_train<-training(split_data)

mv_test<-testing(split_data)
```


## Cross Validation



## Monte Carlo Resampling

Now we're going to do something pretty different. To facili

```{r}
mv_rs<-mc_cv(mv_train,times=25) ## More like 1000 in practice
```


## Lasso for Feature Selection

Adding/dropping variables

Upweighting/downweighting

Lasso-- choosing one among many correlated variables

Ridge-- "shrinking" estimates for many correlated variables

 Penalty<1, mixture=0 is Ridge

 Penalty<1, mixture=1 is Lasso

Anything where mixture is not 0 or 1 is called elastic net, combining the two. 

## Defining a Lasso Model

```{r}
penalty_spec<-.25

mixture_spec<-1

lasso_fit<- 
  linear_reg(penalty=penalty_spec,
             mixture=mixture_spec) %>% 
  set_engine("glmnet")


```

## Define the Workflow

```{r}
movie_wf<-workflow()
```

## Add the Model

```{r}
movie_wf<-movie_wf%>%
  add_model(lasso_fit)
```

## Set Formula

Dot notation

```{r}
movie_formula<-as.formula("log_gross~.")
```

## Recipe


```{r}
movie_rec<-recipe(movie_formula,mv)%>%
  update_role(-title,new_role="predictor")%>% 
  update_role(log_gross,new_role="outcome")%>%
  update_role(title,new_role="id variable")%>%
  step_log(budget)%>% 
  step_other(all_nominal(),threshold = .01)%>%
  step_dummy(all_nominal())%>%
  step_normalize(all_predictors())%>%
  step_naomit(all_predictors())
```


```{r}
movie_wf<-movie_wf%>%
  add_recipe(movie_rec)
```

## Fit resamples

```{r}
movie_lasso_fit<-movie_wf%>%
  fit_resamples(mv_rs)
```

## Examine resamples and fit

```{r}
movie_lasso_fit%>%
  collect_metrics()
```

## CV results
```{r}
movie_lasso_fit%>%
  unnest(.metrics)%>%
  filter(.metric=="rmse")%>%
  ggplot(aes(x=.estimate))+
  geom_density()
```

## Finalize Workflow
```{r}
movie_lasso_final <- finalize_workflow(movie_wf,
                                      select_best(movie_lasso_fit,metric="rmse")) %>%
  fit(mv)
```

## Parameter Estimates
```{r}
movie_lasso_final%>%
  pull_workflow_fit()%>%
  tidy()%>%
  kable()
```


## Prediction in the testing dataset

```{r}
movie_lasso_final%>%last_fit(split_data)%>%
  collect_metrics()
```


## Model Tuning

```{r}
lasso_tune_fit<- 
  linear_reg(penalty=tune(),mixture=mixture_spec)%>% 
  set_engine("glmnet")
```


##  Update Workflow
```{r}
movie_wf<-movie_wf%>%
  update_model(lasso_tune_fit)
```

## Create Grid for Model Tuning
```{r}
lasso_grid<-grid_regular(parameters(lasso_tune_fit) ,levels=10)
```

## Fit Using the Grid
```{r}
movie_lasso_tune_fit <- 
  movie_wf %>%
    tune_grid(mv_rs,grid=lasso_grid)
```

## Examine Results

```{r}
movie_lasso_tune_fit%>%
  collect_metrics()%>%
  filter(.metric=="rmse")%>%
  arrange(mean)
```

## Plot Results

```{r}
movie_lasso_tune_fit%>%
unnest(.metrics)%>%
  filter(.metric=="rmse")%>%
  mutate(tune_id=paste0("penalty=",prettyNum(penalty,digits=4))) %>%
  select(tune_id,.estimate)%>%
  rename(RMSE=.estimate)%>%
  ggplot(aes(x=RMSE,color=tune_id,fill=tune_id))+
  geom_density(alpha=.1)
```

## Choose best model and fit to training data
```{r}
movie_final<-
  finalize_workflow(movie_wf,
                    select_best(movie_lasso_tune_fit,
                                metric="rmse"))%>%
  fit(mv_train)
```

## Examine Parameter Estimates

```{r}
movie_final%>%
  pull_workflow_fit()%>%
  tidy()%>%
  mutate(penalty=prettyNum(penalty,digits=4))%>%
  kable()
```


## Make Prediction

```{r}
pred_df<-movie_final%>%
  predict(mv_test)%>%
  rename(`Predicted Gross`=.pred)%>%
  bind_cols(mv_test)%>%
  rename(`Actual Gross`=log_gross)
```

```{r}
rmse_final<-yardstick::rmse(pred_df,truth = `Actual Gross`,estimate = `Predicted Gross`)

rmse_final
```


```{r}
gg<-pred_df%>%
  ggplot(aes(y=`Actual Gross`,x=`Predicted Gross`,text=title))+
  geom_point(alpha=.25,size=.5)+
  scale_x_continuous(trans="log",labels=label_dollar())+
  scale_y_continuous(trans="log",labels=label_dollar()) 
  

ggplotly(tooltip = "text")

```

Or Just
```{r}
movie_final%>%last_fit(split_data)%>%
  collect_metrics()
```


## Choose best model and fit to full data
```{r}
movie_final<-
  finalize_workflow(movie_wf,
                    select_best(movie_lasso_tune_fit,
                                metric="rmse"))%>%
  fit(mv) ## FULL dataset
```

```{r}
movie_final%>%
  pull_workflow_fit()%>%
  tidy()%>%
  mutate(penalty=prettyNum(penalty))%>%
  kable()
```

This is what we would use for any incoming data.Let's say the proposal is to make either a horror 
or adventure movie for 10 million. We've also been pitched movies that will be rated R-- which of course better reflects the director's "artistic vision" and movies that will be rated PG-13. Let's see what our model says about these. 

```{r}
newdata<-data_grid(mv,
          log_gross=1,         
          budget=1e7,
          rating=c("R","PG-13"),
          genre=c("Horror","Adventure"),
          runtime=100,
          year=as_factor(2020),
          title="Data Science: The Tuning")

movie_final%>%
  predict(newdata)%>%
  bind_cols(newdata)%>%
  mutate(low_dollar_amount=dollar(exp(.pred-rmse_final$.estimate)))%>%
  mutate(mean_dollar_amount=dollar(exp(.pred)))%>%
  mutate(hi_dollar_amount=dollar(exp(.pred+rmse_final$.estimate)))
  
```

